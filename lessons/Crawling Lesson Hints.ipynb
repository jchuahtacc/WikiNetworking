{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling Lesson Hints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marvel Cinematic Universe\n",
    "\n",
    "##### First list\n",
    "[List of all MCU Actors](https://en.wikipedia.org/wiki/List_of_Marvel_Cinematic_Universe_film_actors)\n",
    "\n",
    "CSS selector: `th`\n",
    "\n",
    "This contains links to both characters and actors\n",
    "\n",
    "##### Second list\n",
    "[List of all Marvel Comics characters](https://en.wikipedia.org/wiki/List_of_Marvel_Comics_characters)\n",
    "\n",
    "CSS selector: `.hatnote`\n",
    "\n",
    "This is a multi-page list of lists, where each article URL begins with  `https://en.wikipedia.org/wiki/List_of_Marvel_Comics_characters:_` and ends with any of the values from ['ABCDEFGHIJKLMNOPQRSTUVWXYZ'] and '0-9'. Therefore, we must construct a list of URLs of each individual list and do a multi-page retrieval.\n",
    "\n",
    "##### Visualization notes\n",
    "\n",
    "This is an extremely dense graph, due to the number of links between any two articles. An undirected graph (which sums links back and forth between two articles as a single weighted edge) with a minimum weight greater than 1 helps cut down on clutter. In addition, a `spring_layout` creates some interesting groupings of individual articles.\n",
    "\n",
    "##### Data files\n",
    "\n",
    "[`mcu_network.json`](./mcu_network.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BET Hip Hop Award Winners\n",
    "\n",
    "##### First list: \n",
    "\n",
    "[List of all Hip Hop musicians](https://en.wikipedia.org/wiki/List_of_hip_hop_musicians)\n",
    "\n",
    "CSS selector: `li`\n",
    "\n",
    "This contains links to all Hip Hop musicians with a Wiki article.\n",
    "\n",
    "##### Second list:\n",
    "\n",
    "[List of all BET Hip Hop awards](https://en.wikipedia.org/wiki/BET_Hip_Hop_Awards)\n",
    "\n",
    "CSS selector: `li`\n",
    "\n",
    "This contains links to all BET Award Winner musicians and the names of the works for which they won an award.\n",
    "\n",
    "##### Crawling notes\n",
    "\n",
    "Crawling and saving the graph as an undirected graph and as a directed graph can generate extremely different visualizations.\n",
    "\n",
    "##### Visualization notes\n",
    "\n",
    "When the graph is flattened as a directed graph and then visualized as a directed graph with minimum weight of 2, a number of artists are forced to outside of the graph in a ring shape.\n",
    "\n",
    "##### Data files\n",
    "\n",
    "[`bet_directed.json`](./bet_directed.json) and [`bet_undirected.json`](./bet_undirected.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forbes 400\n",
    "\n",
    "\n",
    "##### Crawling notes\n",
    "The [Forbes 400 Wikipedia](https://en.wikipedia.org/wiki/List_of_members_of_the_Forbes_400) entry is extremely incomplete. To create the crawl list, you can text mine the [Forbes 400](https://www.forbes.com/sites/chasewithorn/2016/10/04/forbes-400-the-full-list-of-the-richest-people-in-america-2016/#3c2f82d422f4) list directly. Each entry is contained inside of a `strong` tag and matches a pattern that begins with a number, followed by a period. To convert this data into a useable list of Wikipedia articles, use the following code:\n",
    "\n",
    "```\n",
    "from pyquery import PyQuery\n",
    "\n",
    "# Make a list of URLs to mine\n",
    "urls = [ \"https://www.forbes.com/sites/chasewithorn/2016/10/04/forbes-400-the-full-list-of-the-richest-people-in-america-2016/#3381da7c22f4\",\n",
    "         \"https://www.forbes.com/sites/chasewithorn/2016/10/04/forbes-400-the-full-list-of-the-richest-people-in-america-2016/2/#1bf172cb7b17\", \n",
    "         \"https://www.forbes.com/sites/chasewithorn/2016/10/04/forbes-400-the-full-list-of-the-richest-people-in-america-2016/3/#5722e9247c58\", \n",
    "         \"https://www.forbes.com/sites/chasewithorn/2016/10/04/forbes-400-the-full-list-of-the-richest-people-in-america-2016/4/#3262ecd31473\"]\n",
    "\n",
    "strongs = list()\n",
    "\n",
    "# Get each \"strong\" HTML tag from each url\n",
    "for url in urls:\n",
    "    strongs.extend(PyQuery(url=url)(\"strong\"))\n",
    "\n",
    "# Use regular expressions to do the heavy lifting\n",
    "import re\n",
    "\n",
    "# This regex matches any number of digits followed by a period and a space, then accepts the rest of the string\n",
    "regex = re.compile(\"^\\d+\\. .+\")\n",
    "\n",
    "# Use another regex to delete the list number, replace any spaces with an underscore\n",
    "forbes_400 = [ \"/wiki/\" + re.sub(\"^\\d+\\. \", \"\", strong.text).replace(\" \", \"_\") \\\n",
    "                for strong in strongs if strong.text and regex.match(strong.text) ]\n",
    "\n",
    "print forbes_400\n",
    "```\n",
    "\n",
    "You may then perform the crawl with `max_articles=400`.\n",
    "\n",
    "_*Note*_: Not all entries will be real Wikipedia entries. This code may generate some error messages during the crawl.\n",
    "\n",
    "##### Visualization notes\n",
    "\n",
    "When creating the graph, a `minimum_weight=3` will create clusters of individuals with business or family ties to each other.\n",
    "\n",
    "##### Data files\n",
    "\n",
    "[`forbes_400.json`](./forbes_400.json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
